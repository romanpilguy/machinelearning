# machinelearning
<h2>Сравнение глубокой сверточной сети и многослойного перцептрона</h2>
Сети создаются на языке python с использованием библиотек Theano и Keras на платформе Google Colaborations с использованием GPU (1xTesla K80 , compute 3.7, having 2496 CUDA cores , 12GB GDDR5 VRAM)
Модели сравниваются на датасете EMNIST - наборе рукописных букв латинского алфавита

<h2>Многослойный перцептрон</h2>
<h3>Первоначальная структура</h3>
Вход - 784 нейрона,
3 скрытых слоя: 1500, 2000, 1000, 26 выходных нейрона
<h4>Первая попытка обучения</h4>
  Используются следующие параметры обучения:
  batch_size = 128
  epochs = 15
  
  Применяется дропаут 0,25 между вторым и третьим скрытыми слоями, во всех слоях используется функция активации ReLU, за исключением выходного, в котором используется Softmax. Функция потерь - перекрестная энтропия, оптимизация - градиентный спуск 
 <p> Лог обучения:</p>
 <pre>Train on 93600 samples, validate on 31200 samples
Epoch 1/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.7004 - acc: 0.7833 - val_loss: 0.4943 - val_acc: 0.8452
Epoch 2/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.3338 - acc: 0.8904 - val_loss: 0.4010 - val_acc: 0.8719
Epoch 3/15
93600/93600 [==============================] - 147s 2ms/step - loss: 0.2566 - acc: 0.9121 - val_loss: 0.3490 - val_acc: 0.8871
Epoch 4/15
93600/93600 [==============================] - 148s 2ms/step - loss: 0.2114 - acc: 0.9256 - val_loss: 0.3098 - val_acc: 0.8997
Epoch 5/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.1816 - acc: 0.9353 - val_loss: 0.2699 - val_acc: 0.9179
Epoch 6/15
93600/93600 [==============================] - 143s 2ms/step - loss: 0.1555 - acc: 0.9431 - val_loss: 0.2860 - val_acc: 0.9135
Epoch 7/15
93600/93600 [==============================] - 143s 2ms/step - loss: 0.1364 - acc: 0.9494 - val_loss: 0.2921 - val_acc: 0.9157
Epoch 8/15
93600/93600 [==============================] - 143s 2ms/step - loss: 0.1219 - acc: 0.9538 - val_loss: 0.2913 - val_acc: 0.9136
Epoch 9/15
93600/93600 [==============================] - 143s 2ms/step - loss: 0.1092 - acc: 0.9572 - val_loss: 0.3035 - val_acc: 0.9157
Epoch 10/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.1003 - acc: 0.9602 - val_loss: 0.3171 - val_acc: 0.9153
Epoch 11/15
93600/93600 [==============================] - 145s 2ms/step - loss: 0.0937 - acc: 0.9628 - val_loss: 0.3395 - val_acc: 0.9138
Epoch 12/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.0872 - acc: 0.9650 - val_loss: 0.3262 - val_acc: 0.9180
Epoch 13/15
93600/93600 [==============================] - 145s 2ms/step - loss: 0.0806 - acc: 0.9675 - val_loss: 0.3309 - val_acc: 0.9194
Epoch 14/15
93600/93600 [==============================] - 144s 2ms/step - loss: 0.0747 - acc: 0.9692 - val_loss: 0.3309 - val_acc: 0.9211
Epoch 15/15
93600/93600 [==============================] - 143s 2ms/step - loss: 0.0726 - acc: 0.9702 - val_loss: 0.3436 - val_acc: 0.9204
Test loss: 0.34356227772925285
Test accuracy: 0.920352564102564</pre>

